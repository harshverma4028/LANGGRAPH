{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2644a18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from typing import TypedDict\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "449c3b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85c2173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatAnthropic(model='claude-3-5-sonnet-20241022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c022d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMState(TypedDict):\n",
    "\n",
    "    question: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35a6eddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_qa(state: LLMState) -> LLMState:\n",
    "    \n",
    "    #Extract the question from state\n",
    "    question = state['question']\n",
    "\n",
    "    # form a prompt\n",
    "    prompt = f'Answer the following question{question}'\n",
    "\n",
    "    # ask that question to the LLM\n",
    "    answer = model.invoke(prompt).content\n",
    "\n",
    "    # update the state\n",
    "    state['answer'] = answer\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75b54ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our graph\n",
    "\n",
    "graph = StateGraph(LLMState)\n",
    "\n",
    "# add nodes\n",
    "graph.add_node('llm_qa',llm_qa)\n",
    "\n",
    "# add edge\n",
    "graph.add_edge(START,'llm_qa')\n",
    "graph.add_edge('llm_qa',END)\n",
    "\n",
    "\n",
    "# compile\n",
    "workflow =  graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a7acdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Japan is Tokyo. It has been the capital city since 1868, when it replaced Kyoto as the seat of the Emperor and the national government. Tokyo is the world's most populous metropolitan area and serves as Japan's political, economic, and cultural center.\n"
     ]
    }
   ],
   "source": [
    "# execute\n",
    "\n",
    "inital_state = {'question': 'what is the capital of japan'}\n",
    "\n",
    "final_state = workflow.invoke(inital_state)\n",
    "\n",
    "print(final_state['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccb8fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
